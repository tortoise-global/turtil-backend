name: Deploy Turtil Backend

on:
  push:
    branches:
      - dev
  workflow_dispatch:

env:
  AWS_REGION: ${{ vars.AWS_REGION || 'ap-south-1' }}
  ENVIRONMENT: 'dev'

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment: dev
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Packer
      uses: hashicorp/setup-packer@main
      with:
        version: 'latest'

    - name: Create environment file
      run: |
        cat > .env << EOF
        # Application Configuration
        PROJECT_NAME=${{ secrets.PROJECT_NAME  }}
        VERSION=${{ secrets.VERSION  }}
        ENVIRONMENT=${{ secrets.ENVIRONMENT }}
        DEBUG=${{ secrets.DEBUG  }}
        LOG_LEVEL=${{ secrets.LOG_LEVEL  }}
        PORT=${{ secrets.PORT }}
        
        # Database Configuration
        DATABASE_URL=${{ secrets.DATABASE_URL }}
        
        # Security Configuration
        SECRET_KEY=${{ secrets.SECRET_KEY }}
        ALGORITHM=${{ secrets.ALGORITHM  }}
        CMS_ACCESS_TOKEN_EXPIRE_MINUTES=${{ secrets.CMS_ACCESS_TOKEN_EXPIRE_MINUTES }}
        CMS_REFRESH_TOKEN_EXPIRE_DAYS=${{ secrets.CMS_REFRESH_TOKEN_EXPIRE_DAYS }}
        
        # CORS and Host Configuration
        CORS_ORIGINS=${{ secrets.CORS_ORIGINS }}
        ALLOWED_HOSTS=${{ secrets.ALLOWED_HOSTS }}
        
        # Rate Limiting Configuration
        RATE_LIMIT_CALLS=${{ secrets.RATE_LIMIT_CALLS }}
        RATE_LIMIT_PERIOD=${{ secrets..RATE_LIMIT_PERIOD }}
        
        # OTP Configuration
        DEV_OTP=${{ secrets.DEV_OTP }}
        
        # Upstash Redis Configuration
        UPSTASH_REDIS_URL=${{ secrets.UPSTASH_REDIS_URL }}
        UPSTASH_REDIS_TOKEN=${{ secrets.UPSTASH_REDIS_TOKEN }}
        REDIS_BLACKLIST_TTL=${{ secrets.REDIS_BLACKLIST_TTL }}
        
        # AWS Configuration
        AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION=${{ env.AWS_REGION }}
        AWS_SES_FROM_EMAIL=${{ secrets.AWS_SES_FROM_EMAIL }}
        AWS_SES_REGION=${{ secrets.rs.AWS_SES_REGION }}
        
        # S3 Configuration
        S3_BUCKET_NAME=${{ secrets.S3_BUCKET_NAME }}
        
        # Deployment Configuration
        AUTO_SCALING_GROUP_NAME=${{ secrets.AUTO_SCALING_GROUP_NAME }}
        LAUNCH_TEMPLATE_ID=${{ secrets.LAUNCH_TEMPLATE_ID }}
        LOAD_BALANCER_DNS=${{ secrets.LOAD_BALANCER_DNS }}
        EOF

    - name: Initialize Packer
      run: |
        cd packer
        packer init .

    - name: Validate Packer template
      run: |
        cd packer
        packer validate \
          -var "aws_region=${{ env.AWS_REGION }}" \
          -var "environment=${{ env.ENVIRONMENT }}" \
          -var "instance_type=t4g.xlarge" \
          -var "source_ami=ami-0f4448044b7b1e09b" \
          amazon-linux.pkr.hcl

    - name: Build AMI with Packer
      id: packer-build
      run: |
        cd packer
        # Build AMI and capture the output
        packer build \
          -var "aws_region=${{ env.AWS_REGION }}" \
          -var "environment=${{ env.ENVIRONMENT }}" \
          -var "instance_type=t4g.xlarge" \
          -var "source_ami=ami-0f4448044b7b1e09b" \
          -machine-readable \
          amazon-linux.pkr.hcl | tee packer-output.log
        
        # Extract AMI ID from Packer output
        AMI_ID=$(grep 'artifact,0,id' packer-output.log | cut -d, -f6 | cut -d: -f2)
        
        if [ -z "$AMI_ID" ]; then
          echo "âŒ Failed to extract AMI ID from Packer output"
          echo "Packer output log:"
          cat packer-output.log
          exit 1
        fi
        
        echo "AMI_ID=$AMI_ID" >> $GITHUB_OUTPUT
        echo "New AMI created: $AMI_ID"

    - name: Update Launch Template
      env:
        AMI_ID: ${{ steps.packer-build.outputs.AMI_ID }}
        LAUNCH_TEMPLATE_ID: ${{ secrets.LAUNCH_TEMPLATE_ID }}
      run: |
        if [ -z "$LAUNCH_TEMPLATE_ID" ]; then
          echo "âŒ LAUNCH_TEMPLATE_ID environment variable is not set"
          exit 1
        fi
        
        if [ -z "$AMI_ID" ]; then
          echo "âŒ AMI_ID is empty"
          exit 1
        fi
        
        echo "Updating Launch Template $LAUNCH_TEMPLATE_ID with new AMI $AMI_ID"
        
        # Create new launch template version
        NEW_VERSION=$(aws ec2 create-launch-template-version \
          --launch-template-id $LAUNCH_TEMPLATE_ID \
          --source-version '$Latest' \
          --launch-template-data "{\"ImageId\":\"$AMI_ID\"}" \
          --query 'LaunchTemplateVersion.VersionNumber' \
          --output text)
        
        echo "Created new launch template version: $NEW_VERSION"
        
        # Set new version as default
        aws ec2 modify-launch-template \
          --launch-template-id $LAUNCH_TEMPLATE_ID \
          --default-version $NEW_VERSION
        
        echo "Set version $NEW_VERSION as default"


    - name: Trigger Auto Scaling Group Instance Refresh
      env:
        AUTO_SCALING_GROUP_NAME: ${{ secrets.AUTO_SCALING_GROUP_NAME }}
      run: |
        echo "Checking for existing instance refresh for Auto Scaling Group: $AUTO_SCALING_GROUP_NAME"
        
        # Check for existing instance refresh
        EXISTING_REFRESH=$(aws autoscaling describe-instance-refreshes \
          --auto-scaling-group-name $AUTO_SCALING_GROUP_NAME \
          --query 'InstanceRefreshes[?Status==`InProgress`].InstanceRefreshId' \
          --output text)
        
        if [ -n "$EXISTING_REFRESH" ] && [ "$EXISTING_REFRESH" != "None" ]; then
          echo "Found existing instance refresh in progress: $EXISTING_REFRESH"
          echo "Cancelling existing refresh..."
          aws autoscaling cancel-instance-refresh \
            --auto-scaling-group-name $AUTO_SCALING_GROUP_NAME || true
          
          # Wait a bit for cancellation to process
          echo "Waiting for cancellation to complete..."
          sleep 30
        fi
        
        echo "Starting new instance refresh for Auto Scaling Group: $AUTO_SCALING_GROUP_NAME"
        
        # Start instance refresh
        INSTANCE_REFRESH_ID=$(aws autoscaling start-instance-refresh \
          --auto-scaling-group-name $AUTO_SCALING_GROUP_NAME \
          --preferences '{
            "InstanceWarmup": 300,
            "MinHealthyPercentage": 50,
            "CheckpointPercentages": [50, 100],
            "CheckpointDelay": 600
          }' \
          --query 'InstanceRefreshId' \
          --output text)
        
        echo "Instance refresh started with ID: $INSTANCE_REFRESH_ID"
        
        # Wait for instance refresh to complete
        echo "Waiting for instance refresh to complete..."
        while true; do
          STATUS=$(aws autoscaling describe-instance-refreshes \
            --auto-scaling-group-name $AUTO_SCALING_GROUP_NAME \
            --instance-refresh-ids $INSTANCE_REFRESH_ID \
            --query 'InstanceRefreshes[0].Status' \
            --output text)
          
          echo "Instance refresh status: $STATUS"
          
          if [ "$STATUS" = "Successful" ]; then
            echo "Instance refresh completed successfully!"
            break
          elif [ "$STATUS" = "Failed" ] || [ "$STATUS" = "Cancelled" ]; then
            echo "âŒ Instance refresh failed with status: $STATUS"
            exit 1
          fi
          
          echo "Still in progress... waiting 30 seconds"
          sleep 30
        done

    - name: Verify Deployment
      env:
        AUTO_SCALING_GROUP_NAME: ${{ secrets.AUTO_SCALING_GROUP_NAME }}
        LOAD_BALANCER_DNS: ${{ secrets.LOAD_BALANCER_DNS }}
      run: |
        echo "Verifying deployment..."
        
        # Check Auto Scaling Group instances
        aws autoscaling describe-auto-scaling-groups \
          --auto-scaling-group-names $AUTO_SCALING_GROUP_NAME \
          --query 'AutoScalingGroups[0].Instances[*].[InstanceId,LifecycleState,HealthStatus]' \
          --output table
        
        # Wait for load balancer health checks
        echo "Waiting for load balancer health checks..."
        sleep 120
        
        # Test application health endpoint
        if [ -n "$LOAD_BALANCER_DNS" ]; then
          for i in {1..10}; do
            if curl -f "http://$LOAD_BALANCER_DNS/health" >/dev/null 2>&1; then
              echo "âœ… Application is healthy and accessible via load balancer"
              exit 0
            fi
            echo "Waiting for application to be healthy... ($i/10)"
            sleep 30
          done
          echo "âŒ Application health check failed"
          exit 1
        else
          echo "âš ï¸ Load balancer DNS not configured in secrets, skipping health check"
        fi

    - name: Cleanup old AMIs
      run: |
        echo "Cleaning up old AMIs..."
        
        # Get list of ALL old AMIs for this environment (keeping only the latest one)
        aws ec2 describe-images \
          --owners self \
          --filters "Name=name,Values=turtil-backend-${{ env.ENVIRONMENT }}-*" \
          --query 'sort_by(Images, &CreationDate)[:-1].[ImageId,Name]' \
          --output text | while read ami_id name; do
          if [ -n "$ami_id" ] && [ "$ami_id" != "None" ]; then
            echo "Deregistering old AMI: $ami_id ($name)"
            aws ec2 deregister-image --image-id $ami_id || true
            
            # Also delete associated snapshots
            echo "Finding and deleting snapshots for AMI: $ami_id"
            aws ec2 describe-images --image-ids $ami_id --query 'Images[0].BlockDeviceMappings[*].Ebs.SnapshotId' --output text 2>/dev/null | while read snapshot_id; do
              if [ -n "$snapshot_id" ] && [ "$snapshot_id" != "None" ]; then
                echo "Deleting snapshot: $snapshot_id"
                aws ec2 delete-snapshot --snapshot-id $snapshot_id || true
              fi
            done
          fi
        done
        
        echo "AMI and snapshot cleanup completed"

    - name: Deployment Summary
      env:
        AMI_ID: ${{ steps.packer-build.outputs.AMI_ID }}
      run: |
        echo "ðŸš€ Deployment Summary"
        echo "===================="
        echo "Environment: ${{ env.ENVIRONMENT }}"
        echo "New AMI ID: $AMI_ID"
        echo "AWS Region: ${{ env.AWS_REGION }}"
        echo "Timestamp: $(date)"
        echo "Commit SHA: ${{ github.sha }}"
        echo "===================="